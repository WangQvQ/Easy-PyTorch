{
    "MNIST 数据集": {
        "prefix": "pytorch:torchvision:dataset:MNIST",
        "description": "定义 MNIST 数据集",
        "body": [
            "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)",
            "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor(), download=True)"
        ]
    },
    "CIFAR10 数据集": {
        "prefix": "pytorch:torchvision:dataset:CIFAR10",
        "description": "定义 CIFAR10 数据集",
        "body": [
            "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=True)",
            "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transforms.ToTensor(), download=True)"
        ]
    },
    "数据加载器": {
        "prefix": "pytorch:torchvision:dataloader",
        "description": "创建一个数据加载器",
        "body": [
            "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)",
            "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)"
        ]
    },
    "分类模型训练模板": {
        "prefix": "pytorch:torchvision:train",
        "description": "分类模型训练模板",
        "body": [
            "def train(model, loader, optimizer, loss_fn):",
            "\t\"\"\"",
            "\t\u8bad\u7ec3\u6a21\u578b\u7684\u51fd\u6570",
            "\t:param model: \u8981\u8bad\u7ec3\u7684\u6a21\u578b",
            "\t:param loader: \u6570\u636e\u52a0\u8f7d\u5668",
            "\t:param optimizer: \u4f18\u5316\u5668",
            "\t:param loss_fn: \u635f\u5931\u51fd\u6570",
            "\t\"\"\"",
            "\tmodel.train()  # \u5c06\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bad\u7ec3\u6a21\u5f0f",
            "\ttotal_loss = 0",
            "\tfor inputs, labels in loader:",
            "\t\toptimizer.zero_grad()  # \u6e05\u7a7a\u4e4b\u524d\u7684\u68af\u5ea6",
            "\t\toutputs = model(inputs)  # \u83b7\u53d6\u6a21\u578b\u5bf9\u5f53\u524d\u8f93\u5165\u6279\u6b21\u7684\u8f93\u51fa",
            "\t\tloss = loss_fn(outputs, labels)  # \u8ba1\u7b97\u635f\u5931",
            "\t\tloss.backward()  # \u53cd\u5411\u4f20\u64ad\u8ba1\u7b97\u53c2\u6570\u7684\u68af\u5ea6",
            "\t\toptimizer.step()  # \u6839\u636e\u68af\u5ea6\u66f4\u65b0\u53c2\u6570",
            "\t\ttotal_loss += loss.item()  # \u7d2f\u52a0\u635f\u5931",
            "\taverage_loss = total_loss / len(loader)  # \u8ba1\u7b97\u5e73\u5747\u635f\u5931",
            "\tprint(f'\u8bad\u7ec3\u635f\u5931: {average_loss:.4f}')"
        ]
    },
    "分类模型验证模板": {
        "prefix": "pytorch:torchvision:test",
        "description": "分类模型验证模板",
        "body": [
            "def test(model, loader):",
            "\t\"\"\"",
            "\t\u6d4b\u8bd5\u6a21\u578b\u7684\u51fd\u6570",
            "\t:param model: \u8981\u6d4b\u8bd5\u7684\u6a21\u578b",
            "\t:param loader: \u6570\u636e\u52a0\u8f7d\u5668",
            "\t\"\"\"",
            "\tmodel.eval()  # \u5c06\u6a21\u578b\u8bbe\u7f6e\u4e3a\u8bc4\u4f30\u6a21\u5f0f",
            "\tcorrect = 0",
            "\ttotal = 0",
            "\twith torch.no_grad():  # \u505c\u6b62\u8ba1\u7b97\u68af\u5ea6\uff0c\u8282\u7701\u8ba1\u7b97\u8d44\u6e90\u548c\u5185\u5b58",
            "\t\tfor inputs, labels in loader:",
            "\t\t\toutputs = model(inputs)",
            "\t\t\t_, predicted = torch.max(outputs, 1)  # \u83b7\u53d6\u6982\u7387\u6700\u5927\u7684\u9884\u6d4b\u7ed3\u679c",
            "\t\t\ttotal += labels.size(0)  # \u7d2f\u52a0\u6837\u672c\u603b\u6570",
            "\t\t\tcorrect += (predicted == labels).sum().item()  # \u7d2f\u52a0\u6b63\u786e\u9884\u6d4b\u7684\u6570\u91cf",
            "\taccuracy = 100 * correct / total  # \u8ba1\u7b97\u51c6\u786e\u7387",
            "\tprint(f'\u6d4b\u8bd5\u51c6\u786e\u7387: {accuracy:.2f}%')"
        ]
    },
    "分类模型经典例子": {
        "prefix": "pytorch:torchvision:classification example",
        "description": "分类模型经典例子",
        "body": [
            "import torch",
            "from torch import nn, optim",
            "from torchvision import datasets, transforms",
            "from torch.utils.data import DataLoader",
            "",
            "def initialize_data_loaders(batch_size=64, download=False):",
            "\t\"\"\"\u521d\u59cb\u5316\u5e76\u8fd4\u56de\u8bad\u7ec3\u96c6\u548c\u6d4b\u8bd5\u96c6\u7684\u6570\u636e\u52a0\u8f7d\u5668\"\"\"",
            "\t# \u5b9a\u4e49\u6570\u636e\u8f6c\u6362\u64cd\u4f5c",
            "\ttransform = transforms.ToTensor()",
            "",
            "\t# \u51c6\u5907MNIST\u6570\u636e\u96c6",
            "\ttrain_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=download)",
            "\ttest_dataset = datasets.MNIST(root='./data', train=False, transform=transform, download=download)",
            "",
            "\t# \u6570\u636e\u52a0\u8f7d\u5668",
            "\ttrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)",
            "\ttest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)",
            "",
            "\treturn train_loader, test_loader",
            "",
            "class SimpleNN(nn.Module):",
            "\t\"\"\"\u5b9a\u4e49\u7b80\u5355\u7684\u795e\u7ecf\u7f51\u7edc\u7ed3\u6784\"\"\"",
            "\tdef __init__(self, input_size=784, num_classes=10):",
            "\t\tsuper(SimpleNN, self).__init__()",
            "\t\tself.fc1 = nn.Linear(input_size, num_classes)",
            "   ",
            "\tdef forward(self, x):",
            "\t\tx = x.view(x.size(0), -1)  # \u5c55\u5e73\u56fe\u50cf\u4e3a\u4e00\u7ef4\u5411\u91cf",
            "\t\treturn torch.softmax(self.fc1(x), dim=1)",
            "",
            "def train(model, loader, optimizer, loss_fn):",
            "\t\"\"\"\u8bad\u7ec3\u6a21\u578b\"\"\"",
            "\tmodel.train()",
            "\ttotal_loss = 0",
            "\tfor inputs, labels in loader:",
            "\t\toptimizer.zero_grad()",
            "\t\toutputs = model(inputs)",
            "\t\tloss = loss_fn(outputs, labels)",
            "\t\tloss.backward()",
            "\t\toptimizer.step()",
            "\t\ttotal_loss += loss.item()",
            "\tprint(f'\u8bad\u7ec3\u635f\u5931: {total_loss / len(loader):.4f}')",
            "",
            "def test(model, loader):",
            "\t\"\"\"\u6d4b\u8bd5\u6a21\u578b\"\"\"",
            "\tmodel.eval()",
            "\tcorrect = 0",
            "\ttotal = 0",
            "\twith torch.no_grad():",
            "\t\tfor inputs, labels in loader:",
            "\t\t\toutputs = model(inputs)",
            "\t\t\t_, predicted = torch.max(outputs, 1)",
            "\t\t\ttotal += labels.size(0)",
            "\t\t\tcorrect += (predicted == labels).sum().item()",
            "\tprint(f'\u6d4b\u8bd5\u51c6\u786e\u7387: {100 * correct / total:.2f}%')",
            "",
            "if __name__ == '__main__':",
            "\ttrain_loader, test_loader = initialize_data_loaders(download=True)",
            "\tmodel = SimpleNN()",
            "\tloss_function = nn.CrossEntropyLoss()",
            "\toptimizer = optim.SGD(model.parameters(), lr=0.1)",
            "\tepochs = 3",
            "",
            "\tfor epoch in range(epochs):",
            "\t\tprint(f'Epoch {epoch + 1}/{epochs}:')",
            "\t\ttrain(model, train_loader, optimizer, loss_function)",
            "\t\ttest(model, test_loader)"
        ]
    }
}
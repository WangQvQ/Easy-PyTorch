{
    "SE注意力模块": {
        "prefix": "pytorch:attention:SE",
        "description": "SE 注意力模块",
        "body": [
            "class SE(nn.Module):",
            "\t\"\"\"",
            "\tSqueeze-and-Excitation",
            "\t\u53c2\u6570:",
            "\t- c1: \u8f93\u5165\u7279\u5f81\u901a\u9053\u6570",
            "\t- ratio: \u538b\u7f29\u6bd4\u7387\uff0c\u9ed8\u8ba4\u4e3a16",
            "\t\"\"\"",
            "\tdef __init__(self, c1, ratio=16):",
            "\t\tsuper(SE, self).__init__()",
            "\t\tself.avgpool = nn.AdaptiveAvgPool2d(1)  # \u9002\u5e94\u6027\u5e73\u5747\u6c60\u5316\uff0c\u8f93\u51fa\u5927\u5c0f\u4e3a1x1",
            "\t\tself.l1 = nn.Linear(c1, c1 // ratio, bias=False)  # \u7b2c\u4e00\u5c42\u5168\u8fde\u63a5\u5c42\uff0c\u8fdb\u884c\u7279\u5f81\u538b\u7f29",
            "\t\tself.relu = nn.ReLU(inplace=True)  # ReLU\u6fc0\u6d3b\u51fd\u6570",
            "\t\tself.l2 = nn.Linear(c1 // ratio, c1, bias=False)  # \u7b2c\u4e8c\u5c42\u5168\u8fde\u63a5\u5c42\uff0c\u8fdb\u884c\u7279\u5f81\u6269\u5c55",
            "\t\tself.sig = nn.Sigmoid()  # Sigmoid\u6fc0\u6d3b\u51fd\u6570\uff0c\u8f93\u51fa\u7279\u5f81\u91cd\u6807\u5b9a\u6743\u91cd",
            "",
            "\tdef forward(self, x):",
            "\t\tb, c, _, _ = x.size()  # \u83b7\u53d6\u8f93\u5165\u7684\u6279\u5927\u5c0f\u548c\u901a\u9053\u6570",
            "\t\ty = self.avgpool(x).view(b, c)  # \u6267\u884c\u5168\u5c40\u5e73\u5747\u6c60\u5316\u5e76\u8c03\u6574\u5f62\u72b6\u4ee5\u5339\u914d\u5168\u8fde\u63a5\u5c42\u7684\u8f93\u5165",
            "\t\ty = self.l1(y)  # \u538b\u7f29\u7279\u5f81\u901a\u9053",
            "\t\ty = self.relu(y)  # \u5e94\u7528ReLU\u6fc0\u6d3b\u51fd\u6570",
            "\t\ty = self.l2(y)  # \u6269\u5c55\u7279\u5f81\u901a\u9053",
            "\t\ty = self.sig(y)  # \u901a\u8fc7Sigmoid\u83b7\u53d6\u6bcf\u4e2a\u901a\u9053\u7684\u91cd\u6807\u5b9a\u6743\u91cd",
            "\t\ty = y.view(b, c, 1, 1)  # \u8c03\u6574\u5f62\u72b6\u4ee5\u4fbf\u8fdb\u884c\u5e7f\u64ad",
            "\t\treturn x * y.expand_as(x)  # \u5e94\u7528\u6743\u91cd\u5e76\u8fd4\u56de\u7f29\u653e\u540e\u7684\u7279\u5f81\u56fe"
        ]
    },
    "CBAM注意力模块": {
        "prefix": "pytorch:attention:CBAM",
        "description": "CBAM 注意力模块",
        "body": [
            "class ChannelAttention(nn.Module):",
            "\t\"\"\"",
            "\t\u901a\u9053\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u4f7f\u7528\u5e73\u5747\u6c60\u5316\u548c\u6700\u5927\u6c60\u5316\u6765\u5f3a\u5316\u91cd\u8981\u901a\u9053\u3002",
            "\t\u53c2\u6570:",
            "\t- in_planes: \u8f93\u5165\u901a\u9053\u6570",
            "\t- ratio: \u538b\u7f29\u6bd4\u7387\uff0c\u7528\u4e8e\u51cf\u5c0f\u53c2\u6570\u91cf\u548c\u8ba1\u7b97\u91cf",
            "\t\"\"\"",
            "\tdef __init__(self, in_planes, ratio=16):",
            "\t\tsuper(ChannelAttention, self).__init__()",
            "\t\tself.avg_pool = nn.AdaptiveAvgPool2d(1)  # \u81ea\u9002\u5e94\u5e73\u5747\u6c60\u5316",
            "\t\tself.max_pool = nn.AdaptiveMaxPool2d(1)  # \u81ea\u9002\u5e94\u6700\u5927\u6c60\u5316",
            "\t\tself.f1 = nn.Conv2d(in_planes, in_planes // ratio, 1, bias=False)  # \u901a\u9053\u964d\u7ef4",
            "\t\tself.relu = nn.ReLU()  # \u6fc0\u6d3b\u51fd\u6570",
            "\t\tself.f2 = nn.Conv2d(in_planes // ratio, in_planes, 1, bias=False)  # \u901a\u9053\u5347\u7ef4",
            "\t\tself.sigmoid = nn.Sigmoid()  # Sigmoid\u6fc0\u6d3b\u51fd\u6570\u8f93\u51fa\u901a\u9053\u6743\u91cd",
            "",
            "\tdef forward(self, x):",
            "\t\tavg_out = self.f2(self.relu(self.f1(self.avg_pool(x))))  # \u901a\u8fc7\u5e73\u5747\u6c60\u5316\u8def\u5f84\u5904\u7406",
            "\t\tmax_out = self.f2(self.relu(self.f1(self.max_pool(x))))  # \u901a\u8fc7\u6700\u5927\u6c60\u5316\u8def\u5f84\u5904\u7406",
            "\t\tout = self.sigmoid(avg_out + max_out)  # \u878d\u5408\u4e24\u4e2a\u8def\u5f84\u7684\u8f93\u51fa",
            "\t\treturn out",
            "",
            "class SpatialAttention(nn.Module):",
            "\t\"\"\"",
            "\t\u7a7a\u95f4\u6ce8\u610f\u529b\u6a21\u5757\uff0c\u5173\u6ce8\u4e0d\u540c\u7a7a\u95f4\u4f4d\u7f6e\u7684\u91cd\u8981\u6027\u3002",
            "\t\u53c2\u6570:",
            "\t- kernel_size: \u5377\u79ef\u6838\u5927\u5c0f\uff0c\u53ef\u4ee5\u662f3\u62167",
            "\t\"\"\"",
            "\tdef __init__(self, kernel_size=7):",
            "\t\tsuper(SpatialAttention, self).__init__()",
            "\t\tassert kernel_size in (3, 7), \"kernel size must be 3 or 7\"",
            "\t\tpadding = 3 if kernel_size == 7 else 1  # \u6839\u636e\u6838\u5927\u5c0f\u8c03\u6574\u586b\u5145",
            "\t\tself.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)  # \u5377\u79ef\u64cd\u4f5c",
            "\t\tself.sigmoid = nn.Sigmoid()  # Sigmoid\u6fc0\u6d3b\u51fd\u6570\u8f93\u51fa\u7a7a\u95f4\u6743\u91cd",
            "",
            "\tdef forward(self, x):",
            "\t\tavg_out = torch.mean(x, dim=1, keepdim=True)  # \u5e73\u5747\u6c60\u5316",
            "\t\tmax_out, _ = torch.max(x, dim=1, keepdim=True)  # \u6700\u5927\u6c60\u5316",
            "\t\tx = torch.cat([avg_out, max_out], dim=1)  # \u878d\u5408\u5e73\u5747\u548c\u6700\u5927\u6c60\u5316\u7684\u7ed3\u679c",
            "\t\tx = self.conv(x)  # \u5bf9\u5408\u5e76\u540e\u7684\u7ed3\u679c\u8fdb\u884c\u5377\u79ef",
            "\t\treturn self.sigmoid(x)  # \u5e94\u7528Sigmoid\u51fd\u6570",
            "",
            "class CBAM(nn.Module):",
            "\t\"\"\"",
            "\tCBAM\u6a21\u5757\uff0c\u96c6\u6210\u901a\u9053\u6ce8\u610f\u529b\u548c\u7a7a\u95f4\u6ce8\u610f\u529b\u3002",
            "\t\u53c2\u6570:",
            "\t- c1: \u8f93\u5165\u901a\u9053\u6570",
            "\t- ratio: \u901a\u9053\u6ce8\u610f\u529b\u538b\u7f29\u6bd4\u7387",
            "\t- kernel_size: \u7a7a\u95f4\u6ce8\u610f\u529b\u5377\u79ef\u6838\u5927\u5c0f",
            "\t\"\"\"",
            "\tdef __init__(self, c1, ratio=16, kernel_size=7):",
            "\t\tsuper(CBAM, self).__init__()",
            "\t\tself.channel_attention = ChannelAttention(c1, ratio)  # \u901a\u9053\u6ce8\u610f\u529b",
            "\t\tself.spatial_attention = SpatialAttention(kernel_size)  # \u7a7a\u95f4\u6ce8\u610f\u529b",
            "",
            "\tdef forward(self, x):",
            "\t\tout = self.channel_attention(x) * x  # \u5e94\u7528\u901a\u9053\u6ce8\u610f\u529b",
            "\t\tout = self.spatial_attention(out) * out  # \u5e94\u7528\u7a7a\u95f4\u6ce8\u610f\u529b",
            "\t\treturn out"
        ]
    },
    "ECA注意力模块": {
        "prefix": "pytorch:attention:ECA",
        "description": "ECA 注意力模块",
        "body": [
            "class ECA(nn.Module):",
            "\t\"\"\"",
            "\tECA (Efficient Channel Attention) \u6a21\u5757\uff0c\u7528\u4e8e\u589e\u5f3a\u7f51\u7edc\u7684\u901a\u9053\u95f4\u4f9d\u8d56\u6027\u3002",
            "\t\u53c2\u6570:",
            "\t- c1: \u8f93\u5165\u901a\u9053\u6570",
            "\t- k_size: \u5377\u79ef\u6838\u5927\u5c0f\uff0c\u63a7\u5236\u611f\u53d7\u91ce\u5927\u5c0f",
            "\t\"\"\"",
            "\tdef __init__(self, c1, k_size=3):",
            "\t\tsuper(ECA, self).__init__()",
            "\t\tself.avg_pool = nn.AdaptiveAvgPool2d(1)  # \u81ea\u9002\u5e94\u5e73\u5747\u6c60\u5316\uff0c\u8f93\u51fa1x1\u7684\u7279\u5f81\u56fe\uff0c\u4ee5\u4fbf\u8fdb\u884c\u5168\u5c40\u7279\u5f81\u63d0\u53d6",
            "\t\tself.conv = nn.Conv1d(",
            "\t\t\t1, 1, kernel_size=k_size, padding=(k_size - 1) // 2, bias=False",
            "\t\t)  # \u4f7f\u75281D\u5377\u79ef\u5904\u7406\u6c60\u5316\u540e\u7684\u7279\u5f81\uff0c\u7528\u4e8e\u751f\u6210\u901a\u9053\u6ce8\u610f\u529b\u6743\u91cd",
            "\t\tself.sigmoid = nn.Sigmoid()  # Sigmoid\u6fc0\u6d3b\u51fd\u6570\uff0c\u7528\u4e8e\u5f52\u4e00\u5316\u6ce8\u610f\u529b\u6743\u91cd",
            "",
            "\tdef forward(self, x):",
            "\t\ty = self.avg_pool(x)  # \u5bf9\u8f93\u5165\u7279\u5f81\u56fe\u8fdb\u884c\u5168\u5c40\u5e73\u5747\u6c60\u5316",
            "\t\t# \u5c06\u6c60\u5316\u540e\u7684\u7279\u5f81\u8fdb\u884c\u5fc5\u8981\u7684\u7ef4\u5ea6\u8f6c\u6362\uff0c\u4ee5\u5339\u914d1D\u5377\u79ef\u7684\u8f93\u5165\u8981\u6c42",
            "\t\ty = self.conv(y.squeeze(-1).transpose(-1, -2)).transpose(-1, -2).unsqueeze(-1)",
            "\t\ty = self.sigmoid(y)  # \u8ba1\u7b97\u6bcf\u4e2a\u901a\u9053\u7684\u6ce8\u610f\u529b\u6743\u91cd",
            "\t\treturn x * y.expand_as(x)  # \u5c06\u6ce8\u610f\u529b\u6743\u91cd\u5e94\u7528\u4e8e\u539f\u59cb\u8f93\u5165\u7279\u5f81\u56fe\uff0c\u8fdb\u884c\u7279\u5f81\u91cd\u6807\u5b9a"
        ]
    },
    "CA注意力模块": {
        "prefix": "pytorch:attention:CA",
        "description": "CA 注意力模块",
        "body": [
            "class h_sigmoid(nn.Module):",
            "\t\"\"\"",
            "\t\u5b9e\u73b0 h-sigmoid \u6fc0\u6d3b\u51fd\u6570\uff0c\u7528\u4e8e\u534f\u8c03\u6ce8\u610f\u529b\u673a\u5236\u4e2d\u7684\u975e\u7ebf\u6027\u8f6c\u6362\u3002",
            "\t\"\"\"",
            "\tdef __init__(self, inplace=True):",
            "\t\tsuper(h_sigmoid, self).__init__()",
            "\t\tself.relu = nn.ReLU6(inplace=inplace)  # \u4f7f\u7528ReLU6\u8fdb\u884c\u88c1\u526a\u64cd\u4f5c",
            "",
            "\tdef forward(self, x):",
            "\t\t# h-sigmoid \u51fd\u6570\u5b9e\u73b0\uff0cx + 3 \u540e\u901a\u8fc7 ReLU6 \u88c1\u526a\u5230 [0, 6] \u533a\u95f4\uff0c\u518d\u9664\u4ee5 6 \u5f52\u4e00\u5316\u5230 [0, 1]",
            "\t\treturn self.relu(x + 3) / 6",
            "",
            "",
            "class h_swish(nn.Module):",
            "\t\"\"\"",
            "\t\u5b9e\u73b0 h-swish \u6fc0\u6d3b\u51fd\u6570\uff0c\u7ed3\u5408 h-sigmoid \u7528\u4e8e\u63d0\u4f9b\u975e\u7ebf\u6027\u6fc0\u6d3b\u3002",
            "\t\"\"\"",
            "\tdef __init__(self, inplace=True):",
            "\t\tsuper(h_swish, self).__init__()",
            "\t\tself.sigmoid = h_sigmoid(inplace=inplace)  # h-sigmoid \u6fc0\u6d3b\u51fd\u6570\u7684\u5b9e\u4f8b",
            "",
            "\tdef forward(self, x):",
            "\t\t# h-swish \u51fd\u6570\u5b9e\u73b0\uff0cx \u4e58\u4ee5 h-sigmoid \u7684\u8f93\u51fa",
            "\t\treturn x * self.sigmoid(x)",
            "",
            "",
            "class CoordAtt(nn.Module):",
            "\t\"\"\"",
            "\t\u5b9e\u73b0\u534f\u8c03\u6ce8\u610f\u529b\u6a21\u5757 (Coordinate Attention)\uff0c\u5173\u6ce8\u7279\u5b9a\u7ef4\u5ea6\u4e0a\u7684\u4fe1\u606f\u3002",
            "\t\u53c2\u6570:",
            "\t- inp: \u8f93\u5165\u901a\u9053\u6570",
            "\t- oup: \u8f93\u51fa\u901a\u9053\u6570",
            "\t- reduction: \u901a\u9053\u964d\u7ef4\u6bd4\u4f8b",
            "\t\"\"\"",
            "\tdef __init__(self, inp, oup, reduction=32):",
            "\t\tsuper(CoordAtt, self).__init__()",
            "\t\tself.pool_h = nn.AdaptiveAvgPool2d((None, 1))  # \u6cbf\u7740\u9ad8\u5ea6\u65b9\u5411\u8fdb\u884c\u81ea\u9002\u5e94\u5e73\u5747\u6c60\u5316",
            "\t\tself.pool_w = nn.AdaptiveAvgPool2d((1, None))  # \u6cbf\u7740\u5bbd\u5ea6\u65b9\u5411\u8fdb\u884c\u81ea\u9002\u5e94\u5e73\u5747\u6c60\u5316",
            "\t\tmip = max(8, inp // reduction)  # \u8ba1\u7b97\u964d\u7ef4\u540e\u7684\u4e2d\u95f4\u901a\u9053\u6570",
            "\t\tself.conv1 = nn.Conv2d(inp, mip, kernel_size=1, stride=1, padding=0)  # \u964d\u7ef4\u5377\u79ef\u5c42",
            "\t\tself.bn1 = nn.BatchNorm2d(mip)  # \u6279\u6807\u51c6\u5316",
            "\t\tself.act = h_swish()  # h-swish \u6fc0\u6d3b\u51fd\u6570",
            "\t\tself.conv_h = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)  # \u9488\u5bf9\u9ad8\u5ea6\u7684\u5377\u79ef",
            "\t\tself.conv_w = nn.Conv2d(mip, oup, kernel_size=1, stride=1, padding=0)  # \u9488\u5bf9\u5bbd\u5ea6\u7684\u5377\u79ef",
            "",
            "\tdef forward(self, x):",
            "\t\tidentity = x  # \u4fdd\u7559\u8f93\u5165\u4f5c\u4e3a\u6b8b\u5dee\u8fde\u63a5\u7684\u4e00\u90e8\u5206",
            "\t\tn, c, h, w = x.size()  # \u83b7\u53d6\u8f93\u5165\u5c3a\u5bf8",
            "\t\tx_h = self.pool_h(x)  # \u9ad8\u5ea6\u65b9\u5411\u7684\u6c60\u5316",
            "\t\tx_w = self.pool_w(x).permute(0, 1, 3, 2)  # \u5bbd\u5ea6\u65b9\u5411\u7684\u6c60\u5316\u5e76\u8c03\u6574\u7ef4\u5ea6",
            "\t\ty = torch.cat([x_h, x_w], dim=2)  # \u5728\u7ef4\u5ea6\u4e0a\u5408\u5e76\u7279\u5f81",
            "\t\ty = self.conv1(y)  # \u901a\u8fc7\u5377\u79ef\u964d\u7ef4",
            "\t\ty = self.bn1(y)  # \u6279\u6807\u51c6\u5316",
            "\t\ty = self.act(y)  # \u6fc0\u6d3b\u51fd\u6570",
            "\t\tx_h, x_w = torch.split(y, [h, w], dim=2)  # \u5206\u79bb\u9ad8\u5ea6\u548c\u5bbd\u5ea6\u65b9\u5411\u7684\u7279\u5f81",
            "\t\tx_w = x_w.permute(0, 1, 3, 2)  # \u8c03\u6574\u7ef4\u5ea6",
            "\t\ta_h = self.conv_h(x_h).sigmoid()  # \u9ad8\u5ea6\u65b9\u5411\u7684\u6ce8\u610f\u529b\u6743\u91cd",
            "\t\ta_w = self.conv_w(x_w).sigmoid()  # \u5bbd\u5ea6\u65b9\u5411\u7684\u6ce8\u610f\u529b\u6743\u91cd",
            "\t\tout = identity * a_w * a_h  # \u5e94\u7528\u6ce8\u610f\u529b\u6743\u91cd\u5e76\u4e0e\u539f\u59cb\u8f93\u5165\u76f8\u4e58",
            "\t\treturn out"
        ]
    }
}